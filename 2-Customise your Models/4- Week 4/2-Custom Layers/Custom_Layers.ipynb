{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daz-Riza-Seriog/Tensorflow_ML/blob/main/2-Customise%20your%20Models/4-%20Week%204/2-Custom%20Layers/Custom_Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0pYgseSPesM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44404b7b-9f4e-4a2c-efd2-a014d3840f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_wHeKOFPesO"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7qDLb4TPesP"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHr0pFOGPesR"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXTCxbnnPesS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuTStDEmPesS"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCNX4YzRPesS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07bb468c-f69e-45c9-97cc-6896e6b56293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[ 0.1355233  -0.08328712 -0.01313725]], shape=(1, 3), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[ 0.06868129,  0.02244756, -0.00260083],\n",
            "       [ 0.09474236, -0.02972884,  0.01908007],\n",
            "       [-0.04554764, -0.06822804, -0.02431686],\n",
            "       [ 0.00971853, -0.00168329, -0.01028165],\n",
            "       [ 0.00792875, -0.00609451,  0.00498202]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
          ]
        }
      ],
      "source": [
        "# Create a custom layer\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "  def __init__(self,units,input_dim):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim,units),\n",
        "                             initializer=\"random_normal\")\n",
        "    self.b = self.add_weight(shape=(units,),\n",
        "                             initializer=\"zeros\")\n",
        "\n",
        "  def call(self,inputs):\n",
        "    return tf.matmul(inputs, self.w)+self.b\n",
        "\n",
        "dense_layer = MyLayer(3,5)\n",
        "x = tf.ones((1,5))\n",
        "print(dense_layer(x))\n",
        "print(dense_layer.weights)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('trainable weights:', len(dense_layer.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsFxkXHHD8nq",
        "outputId": "00c99a03-91a6-4293-825b-4ce5d2631481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable weights: 2\n",
            "non-trainable weights: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ts9jkdnZPesT"
      },
      "outputs": [],
      "source": [
        "# Specify trainable weights\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "  def __init__(self,units,input_dim):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim,units),\n",
        "                             initializer=\"random_normal\",\n",
        "                             trainable=False)\n",
        "    self.b = self.add_weight(shape=(units,),\n",
        "                             initializer=\"zeros\",\n",
        "                             trainable=False)\n",
        "\n",
        "  def call(self,inputs):\n",
        "    return tf.matmul(inputs, self.w)+self.b\n",
        "\n",
        "dense_layer = MyLayer(3,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-_hiO75PesT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4141c5-e00c-422c-c959-7d3806773741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable weights: 0\n",
            "non-trainable weights: 2\n"
          ]
        }
      ],
      "source": [
        "print('trainable weights:', len(dense_layer.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwScnqBAPesT"
      },
      "outputs": [],
      "source": [
        "# Create a custom layer to accumulate means of output values\n",
        "\n",
        "class MyLayerMean(Layer):\n",
        "\n",
        "  def __init__(self,units,input_dim):\n",
        "    super(MyLayerMean, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim,units),\n",
        "                             initializer=\"random_normal\")\n",
        "    self.b = self.add_weight(shape=(units,),\n",
        "                             initializer=\"zeros\")\n",
        "    self.sum_activation = tf.Variable(initial_value = tf.zeros(units,),\n",
        "                                      trainable=False)\n",
        "    self.number_call = tf.Variable(initial_value = 0,\n",
        "                                      trainable=False)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    activations = tf.matmul(inputs, self.w)+self.b\n",
        "    self.sum_activation.assign_add(tf.reduce_sum(activations,axis=0))\n",
        "    self.number_call.assign_add(inputs.shape[0])\n",
        "    return activations, self.sum_activation/tf.cast(self.number_call, tf.float32)\n",
        "\n",
        "dense_layer = MyLayerMean(3,5)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naE80hl-PesT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "905a2f96-dea5-4fad-8701-94ff7a0bdcb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.01409848  0.0519644  -0.07366792]\n",
            "[-0.01409848  0.0519644  -0.07366792]\n"
          ]
        }
      ],
      "source": [
        "# Test the layer\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9o3urscPesT"
      },
      "outputs": [],
      "source": [
        "# Create a Dropout layer as a custom layer\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWQpeZLlPesT"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLU2DhncPesT"
      },
      "outputs": [],
      "source": [
        "# Build the model using custom layers with the model subclassing API\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units=units_1,input_dim=input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units=units_2,input_dim=units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units=units_3,input_dim=units_2)\n",
        "        self.softmax = Softmax()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        return self.softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40B2qY0PPesU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f3d071-a9a7-4a2d-8f77-226c14d9c1a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.01080257 0.03014451 0.02859122 0.03530771 0.0327859  0.01255666\n",
            "  0.02226563 0.00428375 0.0062389  0.01769323 0.03507378 0.01688261\n",
            "  0.00963396 0.03722268 0.01502528 0.04129417 0.01664491 0.02990917\n",
            "  0.00783163 0.00667897 0.01779986 0.01222302 0.02173064 0.01328472\n",
            "  0.01314936 0.10842309 0.06511087 0.01010861 0.01572098 0.02114806\n",
            "  0.01064863 0.03108604 0.01223418 0.0374742  0.01284294 0.01135046\n",
            "  0.0061338  0.03756585 0.00765466 0.0144057  0.02740783 0.00918023\n",
            "  0.01526707 0.01662241 0.00850386 0.0260557 ]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " my_layer_2 (MyLayer)        multiple                  640064    \n",
            "                                                                 \n",
            " my_dropout (MyDropout)      multiple                  0         \n",
            "                                                                 \n",
            " my_layer_3 (MyLayer)        multiple                  4160      \n",
            "                                                                 \n",
            " my_dropout_1 (MyDropout)    multiple                  0         \n",
            "                                                                 \n",
            " my_layer_4 (MyLayer)        multiple                  2990      \n",
            "                                                                 \n",
            " softmax (Softmax)           multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 0\n",
            "Non-trainable params: 647,214\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Instantiate a model object\n",
        "\n",
        "model = MyModel(64,10000,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jfNojTU_HzJv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}