{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daz-Riza-Seriog/Tensorflow_ML/blob/main/2-Customise%20your%20Models/4-%20Week%204/7-Optimizing%20Performacne/Optimizing_Performance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeW_5qa65yKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a1e2bd-f08d-4bcf-effa-a5734891c3cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsANTtsF5yKQ"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQp2UtlJ5yKR"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiVxkRq85yKp"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dm6eX20u5yKp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the custom layers and model\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "  def __init__(self,units):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.w = self.add_weight(shape=(input_shape[-1],self.units),\n",
        "                             initializer=\"random_normal\",\n",
        "                             name=\"kernel\")\n",
        "    self.b = self.add_weight(shape=(self.units,),\n",
        "                             initializer=\"zeros\",\n",
        "                             name=\"bias\")\n",
        "\n",
        "  def call(self,inputs):\n",
        "    return tf.matmul(inputs, self.w)+self.b\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units=units_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units=units_2)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units=units_3)\n",
        "        self.softmax = Softmax()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        return self.softmax(x)"
      ],
      "metadata": {
        "id": "7VftLze559DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rORVHFQH5yKp"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ-EGIrR5yKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662ea704-fcae-4ed5-d7e2-ec775244656e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.03755128 0.02910216 0.0335117  0.00831797 0.0054531  0.05297132\n",
            "  0.02788006 0.05265242 0.02862172 0.02237123 0.00556775 0.0328725\n",
            "  0.01770614 0.0092869  0.0097434  0.00379581 0.03021331 0.00945698\n",
            "  0.06763862 0.00499065 0.02085532 0.05432036 0.00545542 0.00917794\n",
            "  0.00699623 0.0151393  0.00415886 0.01162654 0.02353209 0.00361663\n",
            "  0.00839756 0.0446     0.02063499 0.0228554  0.02444356 0.01320631\n",
            "  0.01445875 0.00748526 0.04991983 0.01773363 0.04038455 0.02422817\n",
            "  0.01475259 0.03736133 0.01052155 0.00443286]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " my_layer (MyLayer)          multiple                  640064    \n",
            "                                                                 \n",
            " my_dropout (MyDropout)      multiple                  0         \n",
            "                                                                 \n",
            " my_layer_1 (MyLayer)        multiple                  4160      \n",
            "                                                                 \n",
            " my_dropout_1 (MyDropout)    multiple                  0         \n",
            "                                                                 \n",
            " my_layer_2 (MyLayer)        multiple                  2990      \n",
            "                                                                 \n",
            " softmax (Softmax)           multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Initialize a new model\n",
        "\n",
        "model = MyModel(64,64,46)\n",
        "print(model(tf.ones((1,10000))))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkiNwyMCELNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be42268a-d997-4380-9aaa-dad9237add04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2110848/2110848 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000, skip_top=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svPyJRoPELNG"
      },
      "outputs": [],
      "source": [
        "# Define the class names\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rxu5aAItQfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c82887-2562-456d-ed18-df6d46a47aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: earn\n"
          ]
        }
      ],
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76LqGCCjtQfR"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krxAhgGltQfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e407b5ee-8f56-4aed-cdf8-ea4b0e6ae6dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "550378/550378 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JipRVezCtQfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf0bfb17-cbc4-4f1a-dfe4-ab08123f1a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "? ? ? ? ? ? result ? ? december acquisition ? space co ? expects earnings per share ? 1987 ? ? 15 ? ? 30 ? per share up ? 70 ? ? ? ? ? ? pretax ? should rise ? nine ? 10 ? ? ? six ? ? ? ? ? rental operation revenues ? 19 ? 22 ? ? ? 12 ? ? ? ? ? cash flow per share this ? should ? ? 50 ? three ? ? ?\n"
          ]
        }
      ],
      "source": [
        "# Print the first data example sentence\n",
        "\n",
        "print(text_news)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9umLgGP-tQfR"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZuPJl5itQfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24a64df-11ba-4c21-bde2-976b220a765a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train: (8982, 10000)\n",
            "Shape of x_test: (2246, 10000)\n"
          ]
        }
      ],
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-WwC9_5tQfR"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJ8ZBpfItQfS"
      },
      "outputs": [],
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwOKC2mL5yKq"
      },
      "outputs": [],
      "source": [
        "# Use the @tf.function decorator\n",
        "\n",
        "@tf.function\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAUgvoYU5yKq"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2N05Z_75yKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c679b2c-2392-41d0-e516-9f9b98b78d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 000: Loss 3.400, Accuracy: 45.669%\n",
            "Epoch 001: Loss 1.937, Accuracy: 61.668%\n",
            "Epoch 002: Loss 1.843, Accuracy: 65.832%\n",
            "Epoch 003: Loss 1.802, Accuracy: 67.992%\n",
            "Epoch 004: Loss 1.774, Accuracy: 68.849%\n",
            "Epoch 005: Loss 1.757, Accuracy: 69.261%\n",
            "Epoch 006: Loss 1.754, Accuracy: 69.962%\n",
            "Epoch 007: Loss 1.735, Accuracy: 70.040%\n",
            "Epoch 008: Loss 1.731, Accuracy: 70.586%\n",
            "Epoch 009: Loss 1.732, Accuracy: 71.098%\n",
            "Duration :177.759\n"
          ]
        }
      ],
      "source": [
        "# Re-run the training loop\n",
        "\n",
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
        "train_dataset = train_dataset.batch(32)\n",
        "\n",
        "# Keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 10\n",
        "weight_decay = 0.005\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "  # Training Loop\n",
        "  for x,y in train_dataset:\n",
        "    #Optimize the model\n",
        "    loss_value, grads = grad(model, x, y, weight_decay)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Compute current losses\n",
        "    epoch_loss_avg(loss_value)\n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "  # End Epoch\n",
        "  train_loss_results.append(epoch_loss_avg.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  print(\"Epoch {:03d}: Loss {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
        "                                                             epoch_loss_avg.result(),\n",
        "                                                             epoch_accuracy.result()))\n",
        "\n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdZwVN1i5yKq"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BCCyqmn5yKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "334ada3e-5bcd-4706-a812-614d8c226d2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def tf__grad(model, inputs, targets, wd):\n",
            "    with ag__.FunctionScope('grad', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "        with ag__.ld(tf).GradientTape() as tape:\n",
            "            loss_value = ag__.converted_call(ag__.ld(loss), (ag__.ld(model), ag__.ld(inputs), ag__.ld(targets), ag__.ld(wd)), None, fscope)\n",
            "        try:\n",
            "            do_return = True\n",
            "            retval_ = (ag__.ld(loss_value), ag__.converted_call(ag__.ld(tape).gradient, (ag__.ld(loss_value), ag__.ld(model).trainable_variables), None, fscope))\n",
            "        except:\n",
            "            do_return = False\n",
            "            raise\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n",
        "print(tf.autograph.to_code(grad.python_function))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}